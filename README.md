# QLearning Exploration

### Year
2022

### Overview
This project was developed in order to assiste professors at the University of Minho, designed to facilitate the learning process of Q-learning concepts for students. It comprises a series of progressively complex Jupyter notebooks that explore Q-learning algorithms, neural networks, and their applications in creating intelligent agents using the Python `gym` library and a custom maze environment.

### Features
- **Basic Q-Learning Implementation**: `QLearning.ipynb` introduces the foundational Q-learning algorithm within a maze context.
- **Neural Networks Introduction**: `NN_Intro.ipynb` provides a beginner-friendly introduction to neural networks and their workings.
- **Deep Q-Learning**: `DeepQLearning_Gym.ipynb` delves into the integration of deep learning with Q-learning to enhance agent decision-making.
- **Double Deep Q-Learning**: `DoubleDeepQLearning_Gym.ipynb` explores the concept of Double Deep Q-Learning, aiming to reduce overestimation in agent evaluations.
- **Priority Experience Replay**: `DoubleDeepQLearningPER_Gym.ipynb` introduces an advanced technique to improve learning efficiency by prioritizing certain experiences.

### How It Works
Each notebook builds upon the last, starting with basic Q-learning principles and advancing through complex concepts such as neural networks and deep learning enhancements. The custom maze environment serves as a practical application for these theories, allowing students to visualize the learning process and effectiveness of different algorithms in real-time.

 The following GIF dynamically illustrates the thought process of the Q-learning agent navigating the maze, showcasing how its decision-making evolves with training through updated arrows and paths.

![trainning gif](https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExYTV1aGI5bDZvOGU3YnQ5ZGM4aHhna3FvcjVsbTYyeWptaGd6M3JsdiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/clGryKAicClCevYfJo/giphy.gif)
